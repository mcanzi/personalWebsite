---
title: "Don't let me be misunderstood. Exploring early speech perception"
description: "PhD project"
tags: ["erp", "perception"]
weight: 1
draft: false
date: 2017-09-22
---

__May 2019__. Massimiliano Canzi. __Don't let me be misunderstood: Exploring early phonological and lexical processing in speech perception__. Talk presented at Manchester Forum in Linguistics (mFiL) 2019.	*The University of Manchester*

__March 2019__. Massimiliano Canzi. __Understanding phonological and lexical mismatch in auditory perception__. Invited talk presented at the Phonetics Laboratory of the *University of Glasgow*.

**Introduction to the study**.

Evidence from event-related potentials (ERP) indicates that phonological and semantic incongruities in online language processing and perception are solved at diff􏰀erent times in the brain (D’Arcy et al. 2004). In particular, the N400 component is greater when semantic mismatch is present in language processing (Kutas and Hillyard 1980; Kutas and Hillyard 1984). The Phonological Mismatch Negatively (PMN) component, on the other hand, is commonly found when unpredictable sound sequences are present in speech (Van Den Brink et al. 2001; Connolly and Phillips 1994). While the N400 peaks at around 400 ms post stimulus-onset, the PMN is found earlier, peaking at around 250-300 ms (D’Arcy et al. 2004; Connolly and Phillips 1994). This order of processing information could suggest a feed-forward model and grammar of perception and processing of language (e.g. McQueen et al. 2009). While it has been argued that the N400 and PMN components are representative of the same type of processing, both relating to some sort of lexical or semantic incongruity in language processing (Diaz and Swaab 2007; Jacquier et al. 2005), evidence has also been provided to support the opposite hypothesis (e.g. Connolly and Phillips 1994; D’Arcy et al. 2004).  

D’arcy (2004) conducted a visual-auditory sentence-matching ERP experiment to investigate the spatial distribution of PMN and N400 responses. Participants were presented with a visual-auditory stimulus pair (e.g. visual: ”A teacher in the classroom”, auditory: ”The teacher is in the school / barn”). The last word of each sentence was changed throughout the experiment in order to alter the level of semantic congruity. Category-exemplar probability was also accounted for when choosing sentence-fi􏰁nal stimuli. While levels of semantic congruity would elicit different amplitudes of the N400 component, low-predictability words have been hypothesised to affect PMN amplitude (D’Arcy et al. 2004). Congruent, predictable stimuli found to elicit neither component. Congruent but unpredictable stimuli elicited a small PMN component, but no N400. It appears that the two components can be in fact separated and attributed to diff􏰀erent levels of processing in language comprehension and perception. One issue with D’arcy’s (2004) and similar studies is that, although PMN and N400 seem to refl􏰂ect two separate aspects of on-line language processing, namely phonological and lexical elaboration respectively, the PMN component is elicited by highly unpredictable words, where predictability is determined by semantic and syntactic context. This fi􏰁nding does not necessarily suggest that the PMN component is related to unpredictable phonological features in speech, but it can only confi􏰁rm that the component is not elicited by semantic incongruity. On the other hand, extensive research has attested the presence of N400 only in tasks where lexical activation is present (Chwilla et al. 1995), which points us in the direction of assuming that lower levels of speech processing should not be able to elicit the component.  

Isolating a single tier of language comprehension and processing (e.g. phonological information) is not always achievable in combination with an ERP experimental paradigm and, in many cases, di􏰀erent ERP components have been found to be connected to multiple aspects of speech and language processing. For instance, the P600 component, known to be elicited by syntactic integration in language comprehension (Kaan et al. 2000), was also found to be elicited by semantic mismatch, similarly to the afore-mentioned N400 component (e.g. Van Herten et al. 2005). While many experiments have managed to separate N400 and PMN in speech perception and processing ERP paradigms, mismatch in phonological pre- dictability is usually caused by semantic or syntactic contexts (e.g. D’Arcy et al. 2004; Connolly and Phillips 1994) or other experimental features (e.g. Connolly et al. 2001), rather than sound-sequence mismatch alone.

The current study aims at investigating the presence of the PMN component (and other pre-lexical components) in a context where predictability of speech sounds is determined by the sequence of speech sounds alone. This is done through a learning paradigm, where participants are prompted to learn a sequence of nonce words, grouped in pairs, where the transitional probability between the two items of the pair is 1. The word-initial syllable of the second item of each pair is sometimes manipulated to create unpredictability. If it is the case that PMN is greater when incongruities in speech sounds are present (Connolly and Phillips 1994), this paradigm should be able to capture this, avoiding any external in􏰂uence by semantic or syntactic context. Word-initial syllables and syllable onsets are considered to be unpredictable and, for this reason, very informative in speech perception and comprehension (Connine et al. 1993). Several studies have been conducted on attentiveness to word- initial syllables by listeners. In particular, Astheimer and Sanders (2011) found that unpredictable syllable/onsets - in passive listening - elicited a higher N1 and, generally, higher attentiveness than highly predictable stimuli (Astheimer and Sanders 2011). The methodology of the current experiment is loosely based on Astheimer and Sanders’ (2011) work, while the focus is on the elicitation of pre-lexical components such as the PMN.
